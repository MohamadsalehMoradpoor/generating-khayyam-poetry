{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36a92b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada65341",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('khayyam.txt', 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40a7668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|برخیز بتا'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d8d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabolaries = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be856beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " '\\r',\n",
       " ' ',\n",
       " '!',\n",
       " '|',\n",
       " '\\xa0',\n",
       " '،',\n",
       " '؟',\n",
       " 'آ',\n",
       " 'أ',\n",
       " 'ئ',\n",
       " 'ا',\n",
       " 'ب',\n",
       " 'ت',\n",
       " 'ث',\n",
       " 'ج',\n",
       " 'ح',\n",
       " 'خ',\n",
       " 'د',\n",
       " 'ذ',\n",
       " 'ر',\n",
       " 'ز',\n",
       " 'س',\n",
       " 'ش',\n",
       " 'ص',\n",
       " 'ض',\n",
       " 'ط',\n",
       " 'ظ',\n",
       " 'ع',\n",
       " 'غ',\n",
       " 'ف',\n",
       " 'ق',\n",
       " 'ل',\n",
       " 'م',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ٌ',\n",
       " 'َ',\n",
       " 'ُ',\n",
       " 'ِ',\n",
       " 'ّ',\n",
       " 'ٔ',\n",
       " 'پ',\n",
       " 'چ',\n",
       " 'ژ',\n",
       " 'ک',\n",
       " 'گ',\n",
       " 'ۀ',\n",
       " 'ی']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabolaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42ea5e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabolaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfe40be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index = {u:i for i, u in enumerate(vocabolaries)}\n",
    "index2char = np.array(vocabolaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c2d5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " '\\r': 1,\n",
       " ' ': 2,\n",
       " '!': 3,\n",
       " '|': 4,\n",
       " '\\xa0': 5,\n",
       " '،': 6,\n",
       " '؟': 7,\n",
       " 'آ': 8,\n",
       " 'أ': 9,\n",
       " 'ئ': 10,\n",
       " 'ا': 11,\n",
       " 'ب': 12,\n",
       " 'ت': 13,\n",
       " 'ث': 14,\n",
       " 'ج': 15,\n",
       " 'ح': 16,\n",
       " 'خ': 17,\n",
       " 'د': 18,\n",
       " 'ذ': 19,\n",
       " 'ر': 20,\n",
       " 'ز': 21,\n",
       " 'س': 22,\n",
       " 'ش': 23,\n",
       " 'ص': 24,\n",
       " 'ض': 25,\n",
       " 'ط': 26,\n",
       " 'ظ': 27,\n",
       " 'ع': 28,\n",
       " 'غ': 29,\n",
       " 'ف': 30,\n",
       " 'ق': 31,\n",
       " 'ل': 32,\n",
       " 'م': 33,\n",
       " 'ن': 34,\n",
       " 'ه': 35,\n",
       " 'و': 36,\n",
       " 'ٌ': 37,\n",
       " 'َ': 38,\n",
       " 'ُ': 39,\n",
       " 'ِ': 40,\n",
       " 'ّ': 41,\n",
       " 'ٔ': 42,\n",
       " 'پ': 43,\n",
       " 'چ': 44,\n",
       " 'ژ': 45,\n",
       " 'ک': 46,\n",
       " 'گ': 47,\n",
       " 'ۀ': 48,\n",
       " 'ی': 49}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d751834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n', '\\r', ' ', '!', '|', '\\xa0', '،', '؟', 'آ', 'أ', 'ئ', 'ا',\n",
       "       'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص',\n",
       "       'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ل', 'م', 'ن', 'ه', 'و', 'ٌ',\n",
       "       'َ', 'ُ', 'ِ', 'ّ', 'ٔ', 'پ', 'چ', 'ژ', 'ک', 'گ', 'ۀ', 'ی'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a1a157a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2char[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bc52c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_integer = np.array([char2index[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "446168d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 12, 20, ..., 49,  1,  0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0880a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5f8f9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4ad0ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\n",
      "ب\n",
      "ر\n",
      "خ\n",
      "ی\n",
      "ز\n",
      " \n",
      "ب\n",
      "ت\n",
      "ا\n"
     ]
    }
   ],
   "source": [
    "for i in char_dataset.take(10):\n",
    "    print(index2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9507282c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=TensorSpec(shape=(30,), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = char_dataset.batch(30, drop_remainder=True)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee205f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> |برخیز بتا بیا ز بهر دل ما\r\n",
      "|ح\n",
      "---> ل کن به جمال خویشتن مشکل ما\r\n",
      "|\n",
      "---> یک کوزه شراب تا به هم نوش کنیم\n"
     ]
    }
   ],
   "source": [
    "for i in sequences.take(3):\n",
    "    print('--->', ''.join(index2char[i.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "009a34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sit(batch):\n",
    "    input_text = batch[:-1]\n",
    "    target_text = batch[1:]\n",
    "    return input_text, target_text\n",
    "dataset = sequences.map(sit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4a2052c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=(TensorSpec(shape=(29,), dtype=tf.int32, name=None), TensorSpec(shape=(29,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da31d249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|برخیز بتا بیا ز بهر دل ما\r\n",
      "|\n",
      "برخیز بتا بیا ز بهر دل ما\r\n",
      "|ح\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(''.join(index2char[i[0].numpy()]))\n",
    "    print(''.join(index2char[i[1].numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f6f07a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(64, 29), dtype=tf.int32, name=None), TensorSpec(shape=(64, 29), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.batch(64, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5639b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabolaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "692a6942",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabolary_size = len(vocabolaries)\n",
    "embedding_dim = 25\n",
    "rnn_unit = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aeece61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocabolary_size, 25),\n",
    "    tf.keras.layers.GRU(1024, return_sequences=True),\n",
    "    tf.keras.layers.Dense(vocabolary_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b41585c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 25)          1250      \n",
      "                                                                 \n",
      " gru (GRU)                   (None, None, 1024)        3228672   \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 50)          51250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,281,172\n",
      "Trainable params: 3,281,172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "171b8478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 66ms/step\n",
      "[[ 1.1216772e-03 -2.7554780e-03 -9.4512384e-04 ... -4.8349025e-03\n",
      "   9.6095179e-04  1.9941560e-03]\n",
      " [ 1.2400657e-03  9.9574425e-04 -1.3991991e-03 ... -1.9555248e-04\n",
      "   5.2148928e-03 -1.4674064e-04]\n",
      " [-1.1573792e-03  5.4802760e-03  1.6255752e-03 ... -2.2589290e-03\n",
      "   4.9562617e-03 -2.9845359e-03]\n",
      " ...\n",
      " [-2.7027156e-04 -4.3290053e-03 -1.1794905e-03 ...  5.6784949e-03\n",
      "  -5.4286155e-03 -1.7461486e-03]\n",
      " [-5.3574331e-05 -2.9755058e-03  2.4312641e-05 ...  7.1092006e-03\n",
      "  -3.4592347e-04  1.3967545e-04]\n",
      " [ 9.9565822e-04 -3.7932012e-03 -2.5426992e-04 ... -8.4391749e-04\n",
      "   7.6627708e-04  2.1886984e-03]]\n"
     ]
    }
   ],
   "source": [
    "for input_text, target_text in dataset.take(1):\n",
    "    output = model.predict(input_text)\n",
    "    print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a99f25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(29, 1), dtype=int64, numpy=\n",
       "array([[38],\n",
       "       [16],\n",
       "       [ 6],\n",
       "       [47],\n",
       "       [40],\n",
       "       [ 8],\n",
       "       [26],\n",
       "       [22],\n",
       "       [40],\n",
       "       [ 9],\n",
       "       [27],\n",
       "       [43],\n",
       "       [13],\n",
       "       [40],\n",
       "       [13],\n",
       "       [45],\n",
       "       [40],\n",
       "       [19],\n",
       "       [29],\n",
       "       [19],\n",
       "       [36],\n",
       "       [ 0],\n",
       "       [16],\n",
       "       [30],\n",
       "       [35],\n",
       "       [ 2],\n",
       "       [39],\n",
       "       [ 8],\n",
       "       [43]], dtype=int64)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si = tf.random.categorical(output[0], num_samples=1)\n",
    "si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9eb90f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38, 16,  6, 47, 40,  8, 26, 22, 40,  9, 27, 43, 13, 40, 13, 45, 40,\n",
       "       19, 29, 19, 36,  0, 16, 30, 35,  2, 39,  8, 43], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(si, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adeeb37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'َح،گِآطسِأظپتِتژِذغذو\\nحفه ُآپ'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(index2char[tf.squeeze(si, axis=-1).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b1698c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.1216772e-03, -2.7554780e-03, -9.4512384e-04,  1.4137855e-03,\n",
       "       -5.4788259e-03,  4.4993372e-03,  4.3929080e-03,  2.3201024e-03,\n",
       "       -3.7120283e-04,  9.4999053e-04,  1.2124276e-03, -8.1880053e-04,\n",
       "       -1.2441836e-03,  3.5518524e-03, -3.8265083e-03, -2.5469675e-03,\n",
       "        1.9241204e-03,  3.9603573e-04, -1.9656394e-03,  2.0249197e-03,\n",
       "        1.7273048e-03,  8.8853622e-04, -5.9465994e-03,  8.4378850e-03,\n",
       "       -1.5465207e-03,  5.3120581e-03, -6.1906585e-03,  7.8680535e-04,\n",
       "        3.0195042e-03,  3.2530373e-03, -4.8523210e-03,  2.9584877e-03,\n",
       "       -1.4797749e-03,  4.1607181e-03,  5.1735959e-04, -2.3956872e-03,\n",
       "        2.1656197e-03,  4.8482576e-03,  1.5829917e-03, -2.7708930e-04,\n",
       "       -1.5890987e-03, -3.8435415e-03,  3.4430774e-04,  2.3822922e-03,\n",
       "        2.9882998e-05, -3.9898711e-03,  2.3829078e-03, -4.8349025e-03,\n",
       "        9.6095179e-04,  1.9941560e-03], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7ba923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_f(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0a35c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='khayyam/checkpoints', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbf004eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(dataset, epochs=10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb471911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'khayyam\\\\checkpoints'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('khayyam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eee41bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocabolary_size, 25),\n",
    "    tf.keras.layers.GRU(1024, return_sequences=True),\n",
    "    tf.keras.layers.Dense(vocabolary_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e078657a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x15c96bbf9d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.load_weights(tf.train.latest_checkpoint('khayyam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a65b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "011323a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 25)          1250      \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, None, 1024)        3228672   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, 50)          51250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,281,172\n",
      "Trainable params: 3,281,172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "713abc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 33), dtype=int32, numpy=\n",
       "array([[12, 35,  2, 34, 11, 33,  2, 17, 18, 11, 36, 34, 18,  2, 15, 11,\n",
       "        34,  2, 36,  2, 17, 20, 18,  2, 46, 21, 49, 34,  2, 12, 20, 13,\n",
       "        20]])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_generate = 1000\n",
    "first_string = 'به نام خداوند جان و خرد کزین برتر'\n",
    "input_eval = [char2index[s] for s in first_string]\n",
    "input_eval = tf.expand_dims(input_eval, 0)\n",
    "input_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a321e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d438176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 375ms/step\n"
     ]
    }
   ],
   "source": [
    "text_generated = []\n",
    "for i in range(10):\n",
    "    predictions = model_2.predict(input_eval)\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "    predicted_ids = tf.random.categorical(predictions, num_samples=1).numpy()\n",
    "    input_eval = tf.expand_dims(tf.squeeze(predicted_ids, axis=-1).numpy(), 0).numpy()\n",
    "    text_generated.append(index2char[tf.squeeze(predicted_ids, axis=-1).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c61f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in text_generated:\n",
    "    print(''.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7a9c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_generated[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
